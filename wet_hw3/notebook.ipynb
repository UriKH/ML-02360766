{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Homework Wet Assignment 3 - Regression",
   "id": "c4d5b224da8a4f27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T10:30:45.069222Z",
     "start_time": "2025-06-24T10:30:44.718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from LinearRegressor import LinearRegressor as LR\n",
    "from test_lr import test_lr\n",
    "from verify_gradients import compare_gradients"
   ],
   "id": "40bb377727528074",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preliminary: Updated Data Loading",
   "id": "51cbac3ee08cbeaf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load data",
   "id": "228183bb59b8f465"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-24T10:30:45.099178Z",
     "start_time": "2025-06-24T10:30:45.077983Z"
    }
   },
   "source": [
    "# load data set\n",
    "def load_data(filename) -> np.ndarray:\n",
    "    with open(f'data/{filename}') as file:\n",
    "        data = pd.read_csv(file)\n",
    "        return data\n",
    "\n",
    "dataset = load_data('virus_data.csv')\n",
    "\n",
    "# divide to train and test using the ID's (same method as in Wet HW 1)\n",
    "id1 = 21\n",
    "id2 = 9\n",
    "train = dataset.sample(frac=0.8, random_state=id1 + id2)\n",
    "test = dataset.drop(train.index)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T10:30:45.433149Z",
     "start_time": "2025-06-24T10:30:45.427634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# make sure data is loaded correctly (commented in submission)\n",
    "# assignment 2 data used\n",
    "\n",
    "# train_hw2_path = '../wet_hw2/data/train_prepared.csv'\n",
    "# test_hw2_path = '../wet_hw2/data/test_prepared.csv'\n",
    "#\n",
    "# def equals(l1, l2):\n",
    "#     return len(l1) == len(l2) and all(v == u for v, u in zip(l1, l2))\n",
    "#\n",
    "#\n",
    "# with open(train_hw2_path) as file:\n",
    "#     train_hw2_data = pd.read_csv(file, index_col=0)\n",
    "#     assert equals(train_hw2_data['patient_id'], train['patient_id'])\n",
    "#\n",
    "# with open(test_hw2_path) as file:\n",
    "#     test_hw2_data = pd.read_csv(file, index_col=0)\n",
    "#     assert equals(test_hw2_data['patient_id'], test['patient_id'])"
   ],
   "id": "6286e59b91002327",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Preprocessing\n",
    "Exactly as done in Wet HW 1."
   ],
   "id": "cc84ebc0486fc69c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T10:31:57.669223Z",
     "start_time": "2025-06-24T10:31:57.649923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_missing_data_stats(ds: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Go over the columns of train and test and check for each column how many missing data is there\n",
    "    Arg: ds - the dataset\n",
    "    returns: a list of the names\n",
    "    \"\"\"\n",
    "\n",
    "    has_nan_columns = {}\n",
    "    for col_name in ds.columns:\n",
    "        column = ds[col_name]\n",
    "\n",
    "        nan_mask = pd.isnull(column) # mark for each line if NaN or not\n",
    "        if nan_mask.any():\n",
    "            has_nan_columns[col_name] = nan_mask.value_counts()[True]\n",
    "    return has_nan_columns\n",
    "\n",
    "\n",
    "print(f'{\" \":10}> Train set - missing data')\n",
    "\n",
    "missing_stats_train = get_missing_data_stats(train)\n",
    "for col_name, missing in missing_stats_train.items():\n",
    "    print(f'in column {col_name} - missing: {missing}')\n",
    "print('-' * 70)\n",
    "\n",
    "print(f'{\" \":10}> Test set - missing data')\n",
    "\n",
    "missing_stats_test = get_missing_data_stats(test)\n",
    "for col_name, missing in missing_stats_test.items():\n",
    "    print(f'in column {col_name} - missing: {missing}')\n",
    "print('-' * 70)\n",
    "\n",
    "for col_name in missing_stats_train.keys():\n",
    "    print(f'The mean of {col_name} is - \\t{train[col_name].mean()}')\n",
    "    print(f'The median of {col_name} is - \\t{train[col_name].median()}')"
   ],
   "id": "d0c5d2864b7bb812",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          > Train set - missing data\n",
      "in column PCR_03 - missing: 53\n",
      "----------------------------------------------------------------------\n",
      "          > Test set - missing data\n",
      "in column PCR_03 - missing: 21\n",
      "----------------------------------------------------------------------\n",
      "The mean of PCR_03 is - \t0.521187504661258\n",
      "The median of PCR_03 is - \t-0.0070285297453213\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T10:33:22.937303Z",
     "start_time": "2025-06-24T10:33:22.924275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for col_name in missing_stats_train.keys():\n",
    "    train[col_name]=train[col_name].fillna('median')\n",
    "\n",
    "for col_name in missing_stats_test.keys():\n",
    "    test[col_name]=test[col_name].fillna('median')\n",
    "\n",
    "missing_stats_train = get_missing_data_stats(train)\n",
    "for col_name, missing in missing_stats_train.items():\n",
    "    print(f'in column {col_name} - missing: {missing}')\n",
    "print('-' * 70)\n",
    "\n",
    "print(f'{\" \":10}> Test set - missing data')\n",
    "\n",
    "missing_stats_test = get_missing_data_stats(test)\n",
    "for col_name, missing in missing_stats_test.items():\n",
    "    print(f'in column {col_name} - missing: {missing}')\n",
    "print('-' * 70)"
   ],
   "id": "fbe2abe5e0eaeb9e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "          > Test set - missing data\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T10:30:46.217027500Z",
     "start_time": "2025-06-24T10:29:29.992714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize(\n",
    "        test: pd.DataFrame,\n",
    "        train: pd.DataFrame,\n",
    "        mm_scale_columns: list,\n",
    "        z_scale_columns: list\n",
    ") -> (pd.DataFrame, pd.DataFrame):\n",
    "    scaler_mm = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler_z = StandardScaler()\n",
    "\n",
    "    scaler_mm.fit(train[mm_scale_columns])\n",
    "    train[mm_scale_columns] = scaler_mm.transform(train[mm_scale_columns])\n",
    "    scaler_mm.fit(test[mm_scale_columns])\n",
    "    test[mm_scale_columns] = scaler_mm.transform(test[mm_scale_columns])\n",
    "\n",
    "    scaler_z.fit(train[z_scale_columns])\n",
    "    train[z_scale_columns] = scaler_z.transform(train[z_scale_columns])\n",
    "    scaler_z.fit(test[z_scale_columns])\n",
    "    test[z_scale_columns] = scaler_z.transform(test[z_scale_columns])\n",
    "    return train, test\n",
    "\n",
    "def fill_nan_with_median(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()  # to avoid modifying original DataFrame\n",
    "    for col_name in get_missing_data_stats(df).keys():\n",
    "        if df[col_name].dtype.kind in 'biufc':  # only numeric types\n",
    "            df[col_name] = df[col_name].fillna('median')\n",
    "    return df\n",
    "\n",
    "# train = fill_nan_with_median(train)\n",
    "\n",
    "# for col_name in get_missing_data_stats(train).keys():\n",
    "#     print(f'The mean of {col_name} is - \\t{train[col_name].mean()}')\n",
    "#     print(f'The median of {col_name} is - \\t{train[col_name].median()}')\n",
    "#\n",
    "for col_name in missing_stats_train.keys():\n",
    "     train[col_name].fillna('median')\n",
    "for col_name in missing_stats_test.keys():\n",
    "     test[col_name].fillna('median')\n",
    "\n",
    "# test = fill_nan_with_median(test)\n",
    "# print(get_missing_data_stats(train))\n",
    "assert get_missing_data_stats(train) == {}\n",
    "assert get_missing_data_stats(test) == {}\n",
    "print('assert success')\n",
    "\n",
    "\n",
    "mm_scale_columns = ['PCR_01', 'PCR_02', 'PCR_04', 'PCR_06', 'PCR_08']\n",
    "z_scale_columns = ['PCR_03', 'PCR_05', 'PCR_07', 'PCR_09', 'PCR_10']\n",
    "train, test = normalize(train, test, mm_scale_columns, z_scale_columns)"
   ],
   "id": "127cc23327393422",
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAssertionError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 41\u001B[39m\n\u001B[32m     37\u001B[39m      test[col_name].fillna(\u001B[33m'\u001B[39m\u001B[33mmedian\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m     39\u001B[39m \u001B[38;5;66;03m# test = fill_nan_with_median(test)\u001B[39;00m\n\u001B[32m     40\u001B[39m \u001B[38;5;66;03m# print(get_missing_data_stats(train))\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m41\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m get_missing_data_stats(train) == {}\n\u001B[32m     42\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m get_missing_data_stats(test) == {}\n\u001B[32m     43\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m'\u001B[39m\u001B[33massert success\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[31mAssertionError\u001B[39m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Section 1: Linear regression implementation",
   "id": "4a55482f91c162f7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### load new division for the dataset",
   "id": "2061ad548d298b20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T10:30:46.220031300Z",
     "start_time": "2025-06-24T10:22:32.893481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# divide to train and test using the ID's (same method as in Wet HW 1)\n",
    "train_new = dataset.sample(frac=0.8)\n",
    "test_new = dataset.drop(train.index)\n",
    "\n",
    "train_new = fill_nan_with_median(train_new)\n",
    "test_new = fill_nan_with_median(test_new)\n",
    "train_new, test_new = normalize(train_new, test_new, mm_scale_columns, z_scale_columns)\n",
    "X_train = train_new.drop(columns=['contamination_level']).to_numpy()\n",
    "Y_train = train_new['contamination_level'].to_numpy()\n",
    "\n",
    "\n",
    "assert np.all(np.isfinite(X_train)), \"X_train contains NaN or Inf\"\n",
    "assert np.all(np.isfinite(Y_train)), \"Y_train contains NaN or Inf\"\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"Y_train shape:\", Y_train.shape)\n",
    "\n",
    "compare_gradients(X_train, Y_train, deltas=np.logspace(-7, -2, 9))"
   ],
   "id": "b771516b342314d0",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fill_nan_with_median' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      2\u001B[39m train_new = dataset.sample(frac=\u001B[32m0.8\u001B[39m)\n\u001B[32m      3\u001B[39m test_new = dataset.drop(train.index)\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m train_new = \u001B[43mfill_nan_with_median\u001B[49m(train_new)\n\u001B[32m      6\u001B[39m test_new = fill_nan_with_median(test_new)\n\u001B[32m      7\u001B[39m train_new, test_new = normalize(train_new, test_new, mm_scale_columns, z_scale_columns)\n",
      "\u001B[31mNameError\u001B[39m: name 'fill_nan_with_median' is not defined"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Q2",
   "id": "141280845e9c037a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T10:30:46.231134700Z",
     "start_time": "2025-06-24T10:00:32.326697Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d44d97f26c2d3741",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
